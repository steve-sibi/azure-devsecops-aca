name: CI
on:
  pull_request:
    paths-ignore:
      - "**/*.md"
      - "docs/**"
  push:
    branches: [ main ]
    paths-ignore:
      - "**/*.md"
      - "docs/**"
concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true


jobs:
  changes:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read
    outputs:
      app_changed: ${{ steps.filter.outputs.app }}
      api_changed: ${{ steps.filter.outputs.api }}
      worker_changed: ${{ steps.filter.outputs.worker }}
      clamav_changed: ${{ steps.filter.outputs.clamav }}
      infra_changed: ${{ steps.filter.outputs.infra }}
      python_changed: ${{ steps.filter.outputs.python }}
      run_pr_scans: ${{ steps.flags.outputs.run_pr_scans }}
      scan_matrix: ${{ steps.scan_matrix.outputs.scan_matrix }}
      scan_matrix_count: ${{ steps.scan_matrix.outputs.scan_matrix_count }}
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0

      - name: Detect app changes
        id: filter
        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3
        with:
          filters: |
            api:
              - "app/api/**"
              - "app/common/**"
            worker:
              - "app/worker/**"
              - "app/common/**"
            clamav:
              - "app/clamav/**"
            app:
              - "app/**"
            infra:
              - "infra/**"
              - "checkov.yml"
            python:
              - "app/**/*.py"
              - "scripts/**/*.py"
              - ".github/scripts/**/*.py"
              - "**/requirements*.txt"
              - "pyproject.toml"

      - name: Expose PR security scan flag
        id: flags
        shell: bash
        env:
          RUN_PR_SECURITY_SCANS: ${{ vars.RUN_PR_SECURITY_SCANS || 'false' }}
        run: |
          echo "run_pr_scans=${RUN_PR_SECURITY_SCANS}" >> "$GITHUB_OUTPUT"

      - name: Build PR scan matrix
        id: scan_matrix
        shell: bash
        env:
          API_CHANGED: ${{ steps.filter.outputs.api }}
          WORKER_CHANGED: ${{ steps.filter.outputs.worker }}
          CLAMAV_CHANGED: ${{ steps.filter.outputs.clamav }}
        run: |
          python3 - <<'PY' >> "$GITHUB_OUTPUT"
          import json
          import os

          def truthy(value: str) -> bool:
              return value.lower() in {"1", "true", "yes", "y", "on"}

          items = []
          if truthy(os.environ.get("API_CHANGED", "")):
              items.append(
                  {
                      "name": "api",
                      "dockerfile": "app/api/Dockerfile",
                      "image": "api:ci",
                      "cache_scope": "api",
                      "trivy_output": "trivy-api.sarif",
                  }
              )
          if truthy(os.environ.get("WORKER_CHANGED", "")):
              items.append(
                  {
                      "name": "worker",
                      "dockerfile": "app/worker/Dockerfile.sidecar",
                      "image": "worker:ci",
                      "cache_scope": "worker",
                      "trivy_output": "trivy-worker.sarif",
                  }
              )
          if truthy(os.environ.get("CLAMAV_CHANGED", "")):
              items.append(
                  {
                      "name": "clamav",
                      "dockerfile": "app/clamav/Dockerfile",
                      "image": "clamav:ci",
                      "cache_scope": "clamav",
                      "trivy_output": "trivy-clamav.sarif",
                  }
              )

          matrix = {"include": items}
          print(f"scan_matrix={json.dumps(matrix)}")
          print(f"scan_matrix_count={len(items)}")
          PY

  actionlint:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Install shellcheck + actionlint
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y shellcheck
          curl -sSfL https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash | bash -s -- latest

          if [[ -x "./actionlint" ]]; then
            echo "ACTIONLINT_BIN=./actionlint" >> "$GITHUB_ENV"
          elif [[ -x "./bin/actionlint" ]]; then
            echo "ACTIONLINT_BIN=./bin/actionlint" >> "$GITHUB_ENV"
          else
            echo "::error::actionlint binary not found after install."
            ls -la
            exit 1
          fi

      - name: Lint workflows
        shell: bash
        run: |
          set -euo pipefail
          "${ACTIONLINT_BIN}" -color .github/workflows/*.yml

  deploy-gate:
    needs: [changes]
    if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read
      id-token: write
    outputs:
      deploy_enabled: ${{ steps.gate.outputs.deploy_enabled }}
      reason: ${{ steps.gate.outputs.reason }}
    steps:
      - name: Decide if deploy should run
        id: decide
        shell: bash
        env:
          DEPLOY_ENABLED: ${{ vars.ACA_DEPLOY_ENABLED || 'false' }}
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        run: |
          set -euo pipefail

          if [ "${DEPLOY_ENABLED,,}" != "true" ]; then
            echo "should_check=false" >> "$GITHUB_OUTPUT"
            echo "reason=deploy_disabled" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if [ -z "$AZURE_CLIENT_ID" ] || [ -z "$AZURE_TENANT_ID" ] || [ -z "$AZURE_SUBSCRIPTION_ID" ]; then
            echo "should_check=false" >> "$GITHUB_OUTPUT"
            echo "reason=missing_azure_secrets" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "should_check=true" >> "$GITHUB_OUTPUT"
          echo "reason=ready" >> "$GITHUB_OUTPUT"

      - name: Azure Login (OIDC)
        if: ${{ steps.decide.outputs.should_check == 'true' }}
        id: login
        continue-on-error: true
        uses: azure/login@1384c340ab2dda50fed2bee3041d1d87018aa5e8 # v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Validate infra presence
        id: gate
        shell: bash
        env:
          SHOULD_CHECK: ${{ steps.decide.outputs.should_check }}
          DECIDE_REASON: ${{ steps.decide.outputs.reason }}
          LOGIN_OK: ${{ steps.login.outcome == 'success' }}
          PREFIX: ${{ vars.ACA_PREFIX || 'devsecopsaca' }}
          RG: ${{ vars.ACA_RESOURCE_GROUP || 'rg-devsecops-aca' }}
        run: |
          set -euo pipefail

          if [ "$SHOULD_CHECK" != "true" ]; then
            echo "deploy_enabled=false" >> "$GITHUB_OUTPUT"
            echo "reason=${DECIDE_REASON}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if [ "$LOGIN_OK" != "true" ]; then
            echo "deploy_enabled=false" >> "$GITHUB_OUTPUT"
            echo "reason=azure_login_failed" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          rg_exists="$(az group exists -n "$RG" 2>/dev/null || echo "false")"
          if [ "$rg_exists" != "true" ]; then
            echo "deploy_enabled=false" >> "$GITHUB_OUTPUT"
            echo "reason=resource_group_missing" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if ! az acr show -g "$RG" -n "${PREFIX}acr" --query name -o tsv >/dev/null 2>&1; then
            echo "deploy_enabled=false" >> "$GITHUB_OUTPUT"
            echo "reason=acr_missing" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "deploy_enabled=true" >> "$GITHUB_OUTPUT"
          echo "reason=ready" >> "$GITHUB_OUTPUT"

  python-quality:
    needs: [changes]
    if: ${{ needs.changes.outputs.python_changed == 'true' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read
    env:
      LOG_DIR: .ci-logs
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6
        with: { python-version: "3.11" }

      - name: Cache pip
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ~/.cache/pip
          key: pip-ubuntu-python-quality-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            pip-ubuntu-python-quality-
            pip-ubuntu-

      - name: Prepare logs
        run: mkdir -p "$LOG_DIR"

      - name: Install ruff + pytest
        run: |
          python -m pip install --upgrade pip
          python -m pip install ruff pytest fastapi starlette python-multipart \
            beautifulsoup4 adblockparser tldextract yara-python \
            azure-servicebus azure-data-tables azure-storage-blob azure-core

      - name: Ruff
        id: ruff
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          ruff check app scripts .github/scripts 2>&1 | tee "$LOG_DIR/ruff.log"
          ruff check tests --ignore E402 2>&1 | tee -a "$LOG_DIR/ruff.log"

      - name: Docs consistency check
        id: docs_check
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          python scripts/ci/check_docs_consistency.py 2>&1 | tee "$LOG_DIR/docs-check.log"

      - name: Python compile check
        id: py_compile
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          python -m compileall app scripts .github 2>&1 | tee "$LOG_DIR/compile.log"

      - name: Pytest
        id: pytest
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          pytest 2>&1 | tee "$LOG_DIR/pytest.log"

      - name: Job summary (python-quality)
        if: ${{ always() }}
        shell: bash
        run: |
          {
            echo "## Python quality"
            echo ""
            echo "| Check | Result |"
            echo "|---|---|"
            echo "| Ruff | ${{ steps.ruff.outcome }} |"
            echo "| Docs consistency | ${{ steps.docs_check.outcome }} |"
            echo "| Compile | ${{ steps.py_compile.outcome }} |"
            echo "| Pytest | ${{ steps.pytest.outcome }} |"
            echo ""

            echo "### Recommended fixes"
            ruff_outcome="${{ steps.ruff.outcome }}"
            compile_outcome="${{ steps.py_compile.outcome }}"
            pytest_outcome="${{ steps.pytest.outcome }}"
            docs_outcome="${{ steps.docs_check.outcome }}"

            if [ "$ruff_outcome" != "success" ]; then
              echo "- Run \`ruff check . --fix\` for safe autofixes (then \`ruff format\` if enabled)."
            fi
            if [ "$docs_outcome" != "success" ]; then
              echo "- Align docs/examples with implemented env vars and endpoints (see \`docs-check.log\`)."
            fi
            if [ "$compile_outcome" != "success" ]; then
              echo "- Fix Python syntax errors (see \`compile.log\`)."
            fi
            if [ "$pytest_outcome" != "success" ]; then
              echo "- Re-run \`pytest -q\` locally and fix failing tests."
            fi
            if [ "$ruff_outcome$docs_outcome$compile_outcome$pytest_outcome" = "successsuccesssuccesssuccess" ]; then
              echo "- No action needed."
            fi
            echo ""

            for f in ruff.log docs-check.log compile.log pytest.log; do
              p="$LOG_DIR/$f"
              if [ -f "$p" ]; then
                echo "<details><summary>$f</summary>"
                echo ""
                echo '```text'
                tail -n 200 "$p"
                echo '```'
                echo "</details>"
                echo ""
              fi
            done
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload logs (python-quality)
        if: ${{ always() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ci-logs-python-quality
          path: ${{ env.LOG_DIR }}
          if-no-files-found: ignore

      - name: Fail if quality checks failed
        if: ${{ always() }}
        shell: bash
        run: |
          if [ "${{ steps.ruff.outcome }}" != "success" ] || \
             [ "${{ steps.py_compile.outcome }}" != "success" ] || \
             [ "${{ steps.pytest.outcome }}" != "success" ]; then
            exit 1
          fi

  iac-and-docker-lint:
    needs: [changes]
    if: ${{ needs.changes.outputs.infra_changed == 'true' || needs.changes.outputs.app_changed == 'true' }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
      security-events: write
    env:
      LOG_DIR: .ci-logs
      TF_PLUGIN_CACHE_DIR: ~/.terraform.d/plugin-cache
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6
        if: >-
          ${{ needs.changes.outputs.infra_changed == 'true'
            && (github.event_name == 'push' && github.ref == 'refs/heads/main'
              || needs.changes.outputs.run_pr_scans == 'true') }}
        with: { python-version: "3.11" }

      - uses: hashicorp/setup-terraform@b9cd54a3c349d3f38e8881555d616ced269862dd # v3

      - name: Cache Terraform plugins
        if: ${{ needs.changes.outputs.infra_changed == 'true' }}
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ${{ env.TF_PLUGIN_CACHE_DIR }}
          key: terraform-ubuntu-${{ hashFiles('infra/.terraform.lock.hcl') }}
          restore-keys: |
            terraform-ubuntu-

      - name: Cache pip (Checkov)
        if: >-
          ${{ needs.changes.outputs.infra_changed == 'true'
            && (github.event_name == 'push' && github.ref == 'refs/heads/main'
              || needs.changes.outputs.run_pr_scans == 'true') }}
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ~/.cache/pip
          key: pip-ubuntu-checkov-${{ hashFiles('checkov.yml') }}
          restore-keys: |
            pip-ubuntu-checkov-
            pip-ubuntu-

      - name: Prepare cache dirs
        if: ${{ needs.changes.outputs.infra_changed == 'true' }}
        run: mkdir -p "$TF_PLUGIN_CACHE_DIR"

      - name: Prepare logs
        run: mkdir -p "$LOG_DIR"

      - name: Terraform fmt (check)
        id: terraform_fmt
        continue-on-error: true
        shell: bash
        if: ${{ needs.changes.outputs.infra_changed == 'true' }}
        run: |
          set -euo pipefail
          terraform fmt -check -recursive infra 2>&1 | tee "$LOG_DIR/terraform-fmt.log"

      - name: Terraform init (backend disabled)
        id: terraform_init
        continue-on-error: true
        shell: bash
        if: ${{ needs.changes.outputs.infra_changed == 'true' }}
        run: |
          set -euo pipefail
          terraform -chdir=infra init -backend=false 2>&1 | tee "$LOG_DIR/terraform-init.log"

      - name: Terraform validate
        id: terraform_validate
        continue-on-error: true
        shell: bash
        if: ${{ needs.changes.outputs.infra_changed == 'true' }}
        run: |
          set -euo pipefail
          terraform -chdir=infra validate -no-color 2>&1 | tee "$LOG_DIR/terraform-validate.log"

      - name: Install Checkov
        if: >-
          ${{ needs.changes.outputs.infra_changed == 'true'
            && (github.event_name == 'push' && github.ref == 'refs/heads/main'
              || needs.changes.outputs.run_pr_scans == 'true') }}
        run: pip install checkov

      - name: Checkov (Terraform â†’ SARIF)
        id: checkov
        if: >-
          ${{ needs.changes.outputs.infra_changed == 'true'
            && (github.event_name == 'push' && github.ref == 'refs/heads/main'
              || needs.changes.outputs.run_pr_scans == 'true') }}
        run: |
          set -euo pipefail
          checkov -d infra --framework terraform --config-file checkov.yml --skip-download --quiet -o sarif --output-file checkov.sarif 2>&1 | tee "$LOG_DIR/checkov.log" || true

      - name: Prepare Checkov SARIF
        id: checkov_sarif
        if: ${{ always() && steps.checkov.outcome != 'skipped' }}
        shell: bash
        run: |
          set -euo pipefail

          sarif_file=""

          if [ -f "checkov.sarif" ]; then
            sarif_file="checkov.sarif"
          elif [ -d "checkov.sarif" ]; then
            sarif_file="$(find checkov.sarif -type f -name '*.sarif' | head -n 1 || true)"
          elif [ -f "results_sarif.sarif" ]; then
            sarif_file="results_sarif.sarif"
          fi

          if [ -n "$sarif_file" ] && [ -s "$sarif_file" ]; then
            cp "$sarif_file" "checkov-results.sarif"
            echo "found=true" >> "$GITHUB_OUTPUT"
            echo "sarif_file=checkov-results.sarif" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "::warning::Checkov did not create a SARIF file."
          echo "found=false" >> "$GITHUB_OUTPUT"
          echo "sarif_file=" >> "$GITHUB_OUTPUT"

      - name: Upload Checkov SARIF
        if: >-
          ${{ always()
            && steps.checkov_sarif.outputs.found == 'true'
            && (github.event_name != 'pull_request' || github.event.pull_request.head.repo.fork == false) }}
        uses: github/codeql-action/upload-sarif@58d4c8134bcf8ae089f888d056501755e0da2b44 # v4
        with:
          sarif_file: ${{ steps.checkov_sarif.outputs.sarif_file }}
          category: checkov-terraform

      - name: Hadolint (API)
        id: hadolint_api
        continue-on-error: true
        if: ${{ needs.changes.outputs.api_changed == 'true' }}
        uses: hadolint/hadolint-action@54c9adbab1582c2ef04b2016b760714a4bfde3cf # v3.1.0
        with:
          dockerfile: app/api/Dockerfile

      - name: Hadolint (Worker)
        id: hadolint_worker
        continue-on-error: true
        if: ${{ needs.changes.outputs.worker_changed == 'true' }}
        uses: hadolint/hadolint-action@54c9adbab1582c2ef04b2016b760714a4bfde3cf # v3.1.0
        with:
          dockerfile: app/worker/Dockerfile.sidecar

      - name: Hadolint (ClamAV)
        id: hadolint_clamav
        continue-on-error: true
        if: ${{ needs.changes.outputs.clamav_changed == 'true' }}
        uses: hadolint/hadolint-action@54c9adbab1582c2ef04b2016b760714a4bfde3cf # v3.1.0
        with:
          dockerfile: app/clamav/Dockerfile

      - name: Job summary (iac-and-docker-lint)
        if: ${{ always() }}
        shell: bash
        run: |
          {
            echo "## IaC & Docker lint"
            echo ""
            echo "| Check | Result |"
            echo "|---|---|"
            echo "| Terraform fmt | ${{ steps.terraform_fmt.outcome }} |"
            echo "| Terraform init | ${{ steps.terraform_init.outcome }} |"
            echo "| Terraform validate | ${{ steps.terraform_validate.outcome }} |"
            echo "| Checkov | ${{ steps.checkov.outcome }} |"
            echo "| Hadolint (API) | ${{ steps.hadolint_api.outcome }} |"
            echo "| Hadolint (Worker) | ${{ steps.hadolint_worker.outcome }} |"
            echo "| Hadolint (ClamAV) | ${{ steps.hadolint_clamav.outcome }} |"
            echo ""

            tf_validate_log="$LOG_DIR/terraform-validate.log"
            if [ -f "$tf_validate_log" ]; then
              warn_count="$(grep -c '^Warning:' "$tf_validate_log" || true)"
              err_count="$(grep -c '^Error:' "$tf_validate_log" || true)"
              echo "### Terraform diagnostics"
              echo "- Warnings: $warn_count"
              echo "- Errors: $err_count"

              deprecated_lines="$(grep -n 'deprecated' "$tf_validate_log" | head -n 20 || true)"
              if [ -n "$deprecated_lines" ]; then
                echo ""
                echo "<details><summary>Terraform deprecations (first 20 matches)</summary>"
                echo ""
                echo '```text'
                printf '%s\n' "$deprecated_lines"
                echo '```'
                echo "</details>"
              fi
              echo ""
            fi

            echo "### Checkov findings"
            checkov_outcome="${{ steps.checkov.outcome }}"
            checkov_sarif="${{ steps.checkov_sarif.outputs.sarif_file }}"
            if [ "$checkov_outcome" = "skipped" ]; then
              echo "- Checkov skipped."
            elif [ -n "$checkov_sarif" ] && [ -f "$checkov_sarif" ]; then
              SARIF_FILE="$checkov_sarif" python - <<'PY'
          import json
          import os
          from pathlib import Path

          sarif = Path(os.environ["SARIF_FILE"])
          data = json.loads(sarif.read_text(encoding="utf-8"))
          runs = data.get("runs") or []
          results = (runs[0].get("results") if runs else []) or []
          print(f"- Results: {len(results)}")
          PY
            else
              echo "- SARIF output not found"
            fi
            echo ""

            echo "### Recommended fixes"
            if [ "${{ steps.terraform_fmt.outcome }}" = "failure" ]; then
              echo "- Run \`terraform fmt -recursive infra\` (then re-run CI)."
            fi
            if [ "${{ steps.terraform_validate.outcome }}" = "failure" ]; then
              echo "- Run \`terraform -chdir=infra init -backend=false\` then \`terraform -chdir=infra validate\` locally."
            fi
            if [ "${{ steps.hadolint_api.outcome }}" = "failure" ] || \
               [ "${{ steps.hadolint_worker.outcome }}" = "failure" ] || \
               [ "${{ steps.hadolint_clamav.outcome }}" = "failure" ]; then
              echo "- Fix Dockerfile lint violations (see Hadolint step logs)."
            fi
            if [ "${{ steps.terraform_fmt.outcome }}" != "failure" ] && \
               [ "${{ steps.terraform_validate.outcome }}" != "failure" ] && \
               [ "${{ steps.hadolint_api.outcome }}" != "failure" ] && \
               [ "${{ steps.hadolint_worker.outcome }}" != "failure" ] && \
               [ "${{ steps.hadolint_clamav.outcome }}" != "failure" ]; then
              echo "- No action needed."
            fi
            echo ""

            for f in terraform-fmt.log terraform-init.log terraform-validate.log checkov.log; do
              p="$LOG_DIR/$f"
              if [ -f "$p" ]; then
                echo "<details><summary>$f</summary>"
                echo ""
                echo '```text'
                tail -n 200 "$p"
                echo '```'
                echo "</details>"
                echo ""
              fi
            done
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload logs (iac-and-docker-lint)
        if: ${{ always() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ci-logs-iac-and-docker-lint
          path: |
            ${{ env.LOG_DIR }}
            checkov-results.sarif
          if-no-files-found: ignore

      - name: Fail if required checks failed
        if: ${{ always() }}
        shell: bash
        run: |
          fail=0
          if [ "${{ steps.terraform_fmt.outcome }}" = "failure" ] || \
             [ "${{ steps.terraform_init.outcome }}" = "failure" ] || \
             [ "${{ steps.terraform_validate.outcome }}" = "failure" ] || \
             [ "${{ steps.hadolint_api.outcome }}" = "failure" ] || \
             [ "${{ steps.hadolint_worker.outcome }}" = "failure" ] || \
             [ "${{ steps.hadolint_clamav.outcome }}" = "failure" ]; then
            fail=1
          fi
          exit "$fail"

  build-and-scan:
    needs: [changes]
    if: >-
      ${{ github.event_name == 'pull_request'
        && needs.changes.outputs.run_pr_scans == 'true'
        && needs.changes.outputs.scan_matrix_count != '0' }}
    runs-on: ubuntu-latest
    timeout-minutes: 25
    permissions:
      contents: read
      security-events: write
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.changes.outputs.scan_matrix) }}
    env:
      LOG_DIR: .ci-logs
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

      - name: Cache Trivy DB
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ~/.cache/trivy
          key: trivy-db-ubuntu
          restore-keys: |
            trivy-db-ubuntu-

      - name: Build/scan/upload ${{ matrix.name }} image
        id: component_flow
        uses: ./.github/actions/build-scan-upload
        with:
          enabled: "true"
          dockerfile: ${{ matrix.dockerfile }}
          image_ref: ${{ matrix.image }}
          cache_scope: ${{ matrix.cache_scope }}
          trivy_output: ${{ matrix.trivy_output }}
          sarif_category: trivy-${{ matrix.name }}
          pull: "false"
          push: "false"
          load: "true"
          upload_sarif: ${{ github.event_name != 'pull_request' || github.event.pull_request.head.repo.fork == false }}

      - name: Prepare logs
        if: ${{ always() }}
        run: mkdir -p "$LOG_DIR"

      - name: Job summary (build-and-scan ${{ matrix.name }})
        if: ${{ always() }}
        shell: bash
        run: |
          {
            echo "## Build & scan (${{ matrix.name }})"
            echo ""
            echo "| Step | Result |"
            echo "|---|---|"
            echo "| Docker build | ${{ steps.component_flow.outputs.build_outcome }} |"
            echo "| Trivy scan | ${{ steps.component_flow.outputs.scan_outcome }} |"
            echo ""

            sarif_file="${{ matrix.trivy_output }}"
            if [ -f "$sarif_file" ]; then
              echo "### Trivy findings"
              python3 - <<PY
          import json
          from pathlib import Path

          sarif = Path("$sarif_file")
          data = json.loads(sarif.read_text(encoding="utf-8"))
          runs = data.get("runs") or []
          results = (runs[0].get("results") if runs else []) or []
          by_level = {}
          for r in results:
            level = r.get("level") or "unknown"
            by_level[level] = by_level.get(level, 0) + 1

          total = len(results)
          print(f"- Results: {total}")
          for level, count in sorted(by_level.items()):
            print(f"- {level}: {count}")
          PY
              echo ""
            fi

            echo "### Recommended fixes"
            echo "- Review GitHub Code Scanning results for details (Trivy SARIF upload)."
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload logs (build-and-scan ${{ matrix.name }})
        if: ${{ always() }}
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ci-logs-build-and-scan-${{ matrix.name }}
          path: |
            ${{ env.LOG_DIR }}
            ${{ matrix.trivy_output }}
          if-no-files-found: ignore

  build-and-push:
    needs: [changes, actionlint, python-quality, iac-and-docker-lint, deploy-gate]
    if: >-
      ${{ always()
        && github.event_name == 'push'
        && github.ref == 'refs/heads/main'
        && needs.changes.outputs.app_changed == 'true'
        && needs.deploy-gate.outputs.deploy_enabled == 'true'
        && needs.iac-and-docker-lint.result == 'success'
        && needs.python-quality.result != 'failure' }}
    runs-on: ubuntu-latest
    timeout-minutes: 25
    permissions:
      contents: read
      id-token: write
      security-events: write
    env:
      LOG_DIR: .ci-logs
      PREFIX: ${{ vars.ACA_PREFIX || 'devsecopsaca' }}
      RG: ${{ vars.ACA_RESOURCE_GROUP || 'rg-devsecops-aca' }}
    outputs:
      acr_login_server: ${{ steps.acr.outputs.login_server }}
      api_image: ${{ steps.images.outputs.api_image }}
      worker_image: ${{ steps.images.outputs.worker_image }}
      clamav_image: ${{ steps.images.outputs.clamav_image }}
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2

      - name: Azure Login (OIDC)
        uses: azure/login@1384c340ab2dda50fed2bee3041d1d87018aa5e8 # v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get ACR login server
        id: acr
        shell: bash
        run: |
          set -euo pipefail
          ACR="$(az acr show -g "${RG}" -n "${PREFIX}acr" --query loginServer -o tsv)"
          echo "login_server=${ACR}" >> "$GITHUB_OUTPUT"

      - name: ACR login
        shell: bash
        run: |
          set -euo pipefail
          az acr login --name "${PREFIX}acr"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

      - name: Cache Trivy DB
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5
        with:
          path: ~/.cache/trivy
          key: trivy-db-ubuntu
          restore-keys: |
            trivy-db-ubuntu-

      - name: Build/scan/upload API image
        uses: ./.github/actions/build-scan-upload
        with:
          enabled: ${{ needs.changes.outputs.api_changed }}
          dockerfile: app/api/Dockerfile
          image_ref: ${{ steps.acr.outputs.login_server }}/${{ env.PREFIX }}-api:${{ github.sha }}
          cache_scope: api
          trivy_output: trivy-api.sarif
          sarif_category: trivy-api

      - name: Build/scan/upload Worker image
        uses: ./.github/actions/build-scan-upload
        with:
          enabled: ${{ needs.changes.outputs.worker_changed }}
          dockerfile: app/worker/Dockerfile.sidecar
          image_ref: ${{ steps.acr.outputs.login_server }}/${{ env.PREFIX }}-worker:${{ github.sha }}
          cache_scope: worker
          trivy_output: trivy-worker.sarif
          sarif_category: trivy-worker

      - name: Build/scan/upload ClamAV image
        uses: ./.github/actions/build-scan-upload
        with:
          enabled: ${{ needs.changes.outputs.clamav_changed }}
          dockerfile: app/clamav/Dockerfile
          image_ref: ${{ steps.acr.outputs.login_server }}/${{ env.PREFIX }}-clamav:${{ github.sha }}
          cache_scope: clamav
          trivy_output: trivy-clamav.sarif
          sarif_category: trivy-clamav

      - name: Set image outputs
        id: images
        shell: bash
        run: |
          set -euo pipefail
          ACR="${{ steps.acr.outputs.login_server }}"
          {
            echo "api_image=${ACR}/${PREFIX}-api:${GITHUB_SHA}"
            echo "worker_image=${ACR}/${PREFIX}-worker:${GITHUB_SHA}"
            echo "clamav_image=${ACR}/${PREFIX}-clamav:${GITHUB_SHA}"
          } >> "$GITHUB_OUTPUT"

  app-deploy:
    name: App Deploy (CD)
    needs: [changes, python-quality, iac-and-docker-lint, build-and-push, deploy-gate]
    if: >-
      ${{ always()
        && github.event_name == 'push'
        && github.ref == 'refs/heads/main'
        && needs.changes.outputs.app_changed == 'true'
        && needs.deploy-gate.outputs.deploy_enabled == 'true'
        && needs.build-and-push.result == 'success'
        && needs.iac-and-docker-lint.result == 'success'
        && needs.python-quality.result != 'failure' }}
    permissions:
      contents: read
      id-token: write
    uses: ./.github/workflows/app-deploy.yml
    secrets: inherit
    with:
      build_images: ${{ 'false' }}
      acr_login_server: ${{ needs.build-and-push.outputs.acr_login_server }}
      api_image: ${{ needs.build-and-push.outputs.api_image }}
      worker_image: ${{ needs.build-and-push.outputs.worker_image }}
      clamav_image: ${{ needs.build-and-push.outputs.clamav_image }}
      deploy_api: ${{ needs.changes.outputs.api_changed }}
      deploy_worker: ${{ needs.changes.outputs.worker_changed }}
      deploy_clamav: ${{ needs.changes.outputs.clamav_changed }}
